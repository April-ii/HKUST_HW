{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aac8c67c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from gym import spaces\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.ppo import MlpPolicy\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from stable_baselines3.common.env_util import make_vec_env\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm.notebook import tqdm \n",
    "from empyrical import sharpe_ratio, sortino_ratio\n",
    "from sb3_contrib import RecurrentPPO\n",
    "from stable_baselines3.common.evaluation import evaluate_policy\n",
    "import talib\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_pacf\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "import itertools\n",
    "import warnings\n",
    "import optuna\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d46fa266",
   "metadata": {},
   "outputs": [],
   "source": [
    "def resample_data(data):\n",
    "    df=data.copy()\n",
    "    # Assuming your DataFrame is named 'df' and it's a cuDF DataFrame\n",
    "    df['time'] = pd.to_datetime(df['time'])\n",
    "    df = df.set_index('time')\n",
    "\n",
    "    # Resample and aggregate for each interval\n",
    "    for interval in ['5T', '15T', '30T']:\n",
    "        resampled = df.resample(interval).agg({'Open': 'first','High': 'max','Low': 'min','Close': 'last','Volume': 'sum'})\n",
    "        # Create new column names based on the interval\n",
    "        label = interval.replace('T', 'min')\n",
    "        df[f'Open_{label}'] = resampled['Open']\n",
    "        df[f'High_{label}'] = resampled['High']\n",
    "        df[f'Low_{label}'] = resampled['Low']\n",
    "        df[f'Close_{label}'] = resampled['Close']\n",
    "        df[f'Volume_{label}'] = resampled['Volume']\n",
    "\n",
    "   # Since resampling might introduce NaNs for periods without data, you might need to handle these\n",
    "   # For example, you can fill NaNs with the last valid observation using fillna(method='ffill')\n",
    "    df = df.fillna(method='ffill')\n",
    "\n",
    "    # Reset the index if needed\n",
    "    df = df.reset_index()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5fc1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_amihud_illiquidity(close, volume):\n",
    "    \"\"\"\n",
    "    Calculate Amihud Illiquidity\n",
    "\n",
    "    Parameters:\n",
    "    close (pd.Series): Series of close prices.\n",
    "    volume (pd.Series): Series of volumes.\n",
    "\n",
    "    Returns:\n",
    "    amihud (pd.Series): Amihud Illiquidity values.\n",
    "    \"\"\"\n",
    "    daily_return = close.pct_change()\n",
    "    amihud = daily_return.abs() / volume\n",
    "    return amihud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f9ffc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_data(data):\n",
    "    stock_data=data.copy()\n",
    "    High=stock_data['High']\n",
    "    Low=stock_data['Low']\n",
    "    Open=stock_data['Open']\n",
    "    Close=stock_data['Close']\n",
    "    Volume=stock_data['Volume']\n",
    "    High5=stock_data['High_5min']\n",
    "    Low5=stock_data['Low_5min']\n",
    "    Close5=stock_data['Close_5min']\n",
    "    Volume5=stock_data['Volume_5min']\n",
    "    High15=stock_data['High_15min']\n",
    "    Low15=stock_data['Low_15min']\n",
    "    Close15=stock_data['Close_15min']\n",
    "    Volume15=stock_data['Volume_15min']\n",
    "    High30=stock_data['High_30min']\n",
    "    Low30=stock_data['Low_30min']\n",
    "    Close30=stock_data['Close_30min']\n",
    "    Volume30=stock_data['Volume_30min']\n",
    "    stock_data['price']=(stock_data['Open']+stock_data['Close']+stock_data['High']+stock_data['Low'])/4\n",
    "    \n",
    "    stock_data['RSI'] = talib.RSI(Close, timeperiod=14)\n",
    "    \n",
    "    # 佳庆指标（Chaikin Oscillator），该指标基于AD曲线的指数移动均线而计算得到。属于趋势型因子\n",
    "    stock_data['ADOSC'] = talib.ADOSC(High, Low, Close, Volume, fastperiod=3, slowperiod=10)\n",
    "    # 平均动向指数，DMI因子的构成部分。属于趋势型因子\n",
    "    stock_data['ADX'] = talib.ADX(High, Low, Close,timeperiod=14)\n",
    "    # 绝对价格振荡指数\n",
    "    stock_data['APO'] = talib.APO(Close, fastperiod=12, slowperiod=26)\n",
    "    # 均势指标\n",
    "    stock_data['BOP'] = talib.BOP(Open, High, Low, Close)\n",
    "    stock_data['SAR'] = talib.SAR(High, Low, acceleration=0.02, maximum=0.2)\n",
    "    # 威廉指标\n",
    "    stock_data['WILLR'] = talib.WILLR(High, Low, Close, timeperiod=14)\n",
    "    # PLUS_DI 更向指示器\n",
    "    stock_data['PLUS_DM'] = talib.PLUS_DM(High, Low, timeperiod=14)\n",
    "\n",
    "    stock_data['SLOWK_30min'],stock_data['SLOWD_30min']=talib.STOCH(High30,Low5,Close30)\n",
    "    stock_data['amihud']=calculate_amihud_illiquidity(stock_data['Close'],stock_data['Volume'])\n",
    "    stock_data['amihud_30min']=calculate_amihud_illiquidity(stock_data['Close_30min'],stock_data['Volume_30min'])\n",
    "    stock_data['VROCP6_5min'] = talib.ROCP(Volume5, timeperiod=6)\n",
    "    stock_data['VROCP6_15min'] = talib.ROCP(Volume15, timeperiod=6)\n",
    "\n",
    "    # Add code to keep only the specified columns\n",
    "    cols_to_keep = ['time','price','Volume', 'amihud', 'SLOWK_30min', 'VROCP6_5min', 'VROCP6_15min', 'amihud_30min','PLUS_DM', 'WILLR', 'RSI', 'APO', 'BOP', 'ADX', 'ADOSC', 'SAR']\n",
    "    stock_data = stock_data[cols_to_keep]\n",
    "\n",
    "    stock_data[np.isinf(stock_data)] = np.nan\n",
    "    stock_data.dropna(inplace=True)\n",
    "    stock_data['time'] = pd.to_datetime(stock_data['time'])\n",
    "    stock_data.set_index('time', inplace=True)\n",
    "\n",
    "    return stock_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c9dd08c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CryptoTradingEnv(gym.Env):\n",
    "    metadata = {'render.modes': ['human', 'system', 'none']}\n",
    "    def __init__(self, df, lookback_window_size=10, initial_balance=25000, commission=0.0005, serial=True,render_mode='none'):\n",
    "        super(CryptoTradingEnv, self).__init__()\n",
    "        self.df = df.dropna()\n",
    "        self.render_mode = render_mode\n",
    "        self.lookback_window_size = lookback_window_size\n",
    "        self.initial_balance = initial_balance\n",
    "        self.commission = commission\n",
    "        self.serial = serial\n",
    "        self.action_space = spaces.MultiDiscrete([3, 10])\n",
    "        self.observation_space = spaces.Box(low=0, high=1, shape=(20, lookback_window_size + 1), dtype=np.float16)\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.balance_list=[self.initial_balance]\n",
    "        \n",
    "    def _get_current_price(self):\n",
    "        #Open=self.df['Open'].values[self.frame_start + self.current_step]\n",
    "        #Close=self.df['Close'].values[self.frame_start + self.current_step]\n",
    "        #High=self.df['High'].values[self.frame_start + self.current_step]\n",
    "        #Low=self.df['Low'].values[self.frame_start + self.current_step]\n",
    "        price=self.df['price'].values[self.frame_start + self.current_step]\n",
    "        return price\n",
    "    \n",
    "    def get_max_volume(self):\n",
    "        return 0.25*self.df['Volume'].values[self.frame_start + self.current_step]\n",
    "    \n",
    "    def _next_observation(self):\n",
    "        end = self.current_step + self.lookback_window_size + 1\n",
    "        scaled_df = self.active_df.values[:end].astype('float64')\n",
    "        scaled_df = self.scaler.fit_transform(scaled_df)\n",
    "        scaled_df = pd.DataFrame(scaled_df, columns=self.df.columns)\n",
    "\n",
    "        cols_to_keep = ['price', 'Volume', 'amihud', 'SLOWK_30min', 'VROCP6_5min', 'VROCP6_15min', 'amihud_30min',\n",
    "                        'PLUS_DM', 'WILLR', 'RSI', 'APO', 'BOP', 'ADX', 'ADOSC', 'SAR']\n",
    "\n",
    "        obs = np.array([scaled_df[col].values[self.current_step:end] for col in cols_to_keep])\n",
    "\n",
    "\n",
    "        scaled_history = self.scaler.fit_transform(self.account_history)\n",
    "\n",
    "        obs = np.append(\n",
    "            obs, scaled_history[:, -(self.lookback_window_size + 1):], axis=0)\n",
    "\n",
    "        return obs\n",
    "\n",
    "    def _reset_session(self):\n",
    "        self.current_step = 0\n",
    "        self.reward_len=0\n",
    "\n",
    "        if self.serial:\n",
    "            self.steps_left = len(self.df) - self.lookback_window_size - 1\n",
    "            self.frame_start = self.lookback_window_size\n",
    "        else:\n",
    "            self.steps_left = np.random.randint(1, MAX_TRADING_SESSION)\n",
    "            self.frame_start = np.random.randint(\n",
    "                self.lookback_window_size, len(self.df) - self.steps_left)\n",
    "\n",
    "        self.active_df = self.df[self.frame_start - self.lookback_window_size:\n",
    "                                 self.frame_start + self.steps_left]\n",
    "        \n",
    "    def reset(self, **kwargs):\n",
    "        self.balance = self.initial_balance\n",
    "        self.net_worth = self.initial_balance\n",
    "        self.btc_held = 0\n",
    "        self._reset_session()\n",
    "\n",
    "        self.account_history = np.repeat([\n",
    "            [self.balance],\n",
    "            [0],\n",
    "            [0],\n",
    "            [0],\n",
    "            [0]\n",
    "        ], self.lookback_window_size + 1, axis=1)\n",
    "        self.trades = []\n",
    "\n",
    "        return self._next_observation()\n",
    "\n",
    "    def _take_action(self, action, current_price):\n",
    "        action_type = action[0]\n",
    "        amount = action[1] / 10\n",
    "        btc_bought = 0\n",
    "        btc_sold = 0\n",
    "        cost = 0\n",
    "        sales = 0\n",
    "        max_volume=self.get_max_volume()\n",
    "        #print('last value: ',self.net_worth)\n",
    "        #print('last hold: ',self.btc_held)\n",
    "        #print('last cash: ', self.balance)\n",
    "        if action_type < 1:\n",
    "            btc_bought = min((self.balance / current_price) * amount,max_volume)\n",
    "            cost = btc_bought * current_price * (1 + self.commission)\n",
    "\n",
    "            self.btc_held += btc_bought\n",
    "            self.balance -= cost\n",
    "\n",
    "        elif action_type < 2:\n",
    "            btc_sold = min(self.btc_held * amount,max_volume)\n",
    "            sales = btc_sold * current_price * (1 - self.commission)\n",
    "\n",
    "            self.btc_held -= btc_sold\n",
    "            self.balance += sales\n",
    "\n",
    "        if btc_sold > 0 or btc_bought > 0:\n",
    "            self.trades.append({'step': self.frame_start + self.current_step,\n",
    "                                'amount': btc_sold if btc_sold > 0 else btc_bought, 'total': sales if btc_sold > 0 else cost,\n",
    "                                'type': \"sell\" if btc_sold > 0 else \"buy\"})\n",
    "\n",
    "        self.net_worth = self.balance + self.btc_held * current_price\n",
    "        self.balance_list.append(self.net_worth)\n",
    "        self.account_history = np.append(self.account_history, [\n",
    "            [self.balance],\n",
    "            [btc_bought],\n",
    "            [cost],\n",
    "            [btc_sold],\n",
    "            [sales]\n",
    "        ], axis=1)\n",
    "\n",
    "\n",
    "    def step(self, action):\n",
    "        #print([self.current_step,self.steps_left,self.reward_len])\n",
    "        current_price = self._get_current_price()\n",
    "\n",
    "        prev_net_worth = self.net_worth\n",
    "\n",
    "        self._take_action(action, current_price)\n",
    "\n",
    "        self.steps_left -= 1\n",
    "        self.current_step += 1\n",
    "\n",
    "        if self.steps_left == 0:\n",
    "        #    self.balance += self.btc_held * current_price\n",
    "        #    self.btc_held = 0\n",
    "\n",
    "            self._reset_session()\n",
    "\n",
    "        obs = self._next_observation()\n",
    "        length=min(11,self.current_step)\n",
    "        balances = np.array(self.balance_list)[-length:]\n",
    "        returns=np.diff(balances)/balances[:-1]\n",
    "        #sharpe = sharpe_ratio(returns)\n",
    "        sortino = sortino_ratio(returns)\n",
    "        if np.isnan(sortino):\n",
    "            sortino=0\n",
    "        if sortino==np.inf:\n",
    "            sortino=10\n",
    "        reward = sortino\n",
    "        self.reward_len+=1\n",
    "        \n",
    "        done = self.net_worth <= 0\n",
    "        \n",
    "        return obs, reward, done, {}\n",
    "    \n",
    "    def render(self, mode='human', **kwargs):\n",
    "        if mode == 'system':\n",
    "            print('Price: ' + str(self._get_current_price()))\n",
    "            print(\n",
    "                'Bought: ' + str(self.account_history[2][self.current_step + self.frame_start]))\n",
    "            print(\n",
    "                'Sold: ' + str(self.account_history[4][self.current_step + self.frame_start]))\n",
    "            print('Net worth: ' + str(self.net_worth))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1f75eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_agent(trial):\n",
    "\n",
    "    data=training_data.copy()\n",
    "    train_size =len(data)-len(testing_data) \n",
    "    train = data[:train_size]\n",
    "    evaluate = data[train_size:]\n",
    "\n",
    "    # Create the training environment\n",
    "    train_env = CryptoTradingEnv(train,initial_balance=14483.7497, commission=0.0005, render_mode='system')\n",
    "\n",
    "    # Define hyperparameters using the trial object\n",
    "    learning_rate = trial.suggest_float(\"learning_rate\", 1e-5, 1e-3, log=True)\n",
    "    n_steps = trial.suggest_categorical(\"n_steps\", [128, 256, 512, 1024, 2048])\n",
    "    gamma = trial.suggest_float(\"gamma\", 0.9, 0.9999, log=True)\n",
    "    gae_lambda = trial.suggest_float(\"gae_lambda\", 0.8, 0.99)\n",
    "    clip_range = trial.suggest_float(\"clip_range\", 0.1, 0.3)\n",
    "    batch_size = trial.suggest_categorical(\"batch_size\", [32, 64, 128, 256])\n",
    "\n",
    "    # Setup the model\n",
    "    model = RecurrentPPO(\"MlpLstmPolicy\", train_env, verbose=0, \n",
    "                learning_rate=learning_rate,\n",
    "                n_steps=n_steps,\n",
    "                gamma=gamma,\n",
    "                gae_lambda=gae_lambda,\n",
    "                clip_range=clip_range,\n",
    "                batch_size=batch_size,\n",
    "                tensorboard_log=\"./tensorboard/\",\n",
    "                device='cuda')\n",
    "    \n",
    "    # Train the model\n",
    "    model.learn(total_timesteps=10000) \n",
    "    eval_env = CryptoTradingEnv(evaluate,initial_balance=14483.7497, commission=0.0005,render_mode='system')\n",
    "    obs = eval_env.reset()\n",
    "    rewards_list,done=[],False\n",
    "    net_worth_list=[]\n",
    "    for _ in range(len(evaluate)):\n",
    "        action, _states = model.predict(obs)\n",
    "        obs, rewards, done, info = eval_env.step(action)\n",
    "        rewards_list.append(rewards)\n",
    "        net_worth_list.append(eval_env.net_worth)\n",
    "        \n",
    "    return np.mean(rewards_list)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e258dc09",
   "metadata": {},
   "outputs": [],
   "source": [
    "ltc_data=pd.read_csv('csv\\\\LTCUSD_1m_ltc_usd_60.csv')\n",
    "resample_ltc=resample_data(ltc_data)\n",
    "ltc_feature=fetch_data(resample_ltc)\n",
    "# Define your date ranges\n",
    "start_date = '2021-09-14 00:00:00'\n",
    "end_date = '2023-04-19 00:00:00'\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "training_data = ltc_feature[start_date:end_date]\n",
    "testing_data = ltc_feature[end_date:][1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "418b2fe0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Run the optimization\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(optimize_agent, n_trials=100)  # Adjust the number of trials\n",
    "\n",
    "# Print the best hyperparameters\n",
    "print(\"Best hyperparameters: \", study.best_trial.params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79dd922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params=study.best_trial.params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ffe260",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the environment with training data\n",
    "train_env = CryptoTradingEnv(training_data,initial_balance=14483.7497, commission=0.0005,render_mode='system')\n",
    "# Assuming best_params contains your optimized hyperparameters\n",
    "model = RecurrentPPO(\"MlpLstmPolicy\", train_env, verbose=1, tensorboard_log=\"./tensorboard/\",\n",
    "                     device='cuda',\n",
    "                     learning_rate=best_params['learning_rate'],\n",
    "                     n_steps=best_params['n_steps'],\n",
    "                     batch_size=best_params['batch_size'],\n",
    "                     gamma=best_params['gamma'],\n",
    "                     gae_lambda=best_params['gae_lambda'],\n",
    "                     clip_range=best_params['clip_range'],\n",
    "                     policy_kwargs=dict(net_arch=[64, 64], activation_fn=torch.nn.ReLU))\n",
    "# Train the agent\n",
    "model.learn(total_timesteps=len(train_env.df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9deeccd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"RecurrentPPO_LTC\")\n",
    "loaded_model = RecurrentPPO.load(\"RecurrentPPO_LTC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dfd41ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_env = CryptoTradingEnv(testing_data, initial_balance=14483.7497, commission=0.0005,render_mode='system')\n",
    "obs = test_env.reset()\n",
    "net_worth_list=[]\n",
    "action_list=[]\n",
    "for _ in tqdm(range(len(testing_data)), desc=\"Testing\"):\n",
    "    action, _states = loaded_model.predict(obs)\n",
    "    action_list.append(action)\n",
    "    obs, rewards, done, info = test_env.step(action)\n",
    "    test_env.render(mode=\"system\")\n",
    "    net_worth_list.append(test_env.net_worth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f43c0236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming testing_data.index is your DatetimeIndex\n",
    "dates = testing_data.index\n",
    "\n",
    "# Calculate the number of days\n",
    "num_days = (dates.max() - dates.min()).days + 1\n",
    "\n",
    "print(f\"Number of days in the index: {num_days}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fdc6783",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_financial_metrics(net_worth_list, num_days, initial_value, action_list):\n",
    "    # Calculate daily returns\n",
    "    returns_list = [(net_worth_list[i] - net_worth_list[i-1]) / net_worth_list[i-1] for i in range(1, len(net_worth_list))]\n",
    "    returns = np.array(returns_list)\n",
    "\n",
    "    # Calculate maximum drawdown\n",
    "    rolling_max = np.maximum.accumulate(net_worth_list)\n",
    "    daily_drawdown = net_worth_list / rolling_max - 1.0\n",
    "    max_drawdown = np.min(daily_drawdown)\n",
    "\n",
    "    # Calculate turnover rate\n",
    "    buys_and_sells = sum(1 for action in action_list if action[0] in [0, 1])\n",
    "    turnover_rate = buys_and_sells / len(net_worth_list)\n",
    "\n",
    "    # Calculate total return\n",
    "    total_return = (net_worth_list[-1] - initial_value) / initial_value\n",
    "\n",
    "    # Calculate annualized total return\n",
    "    annualized_total_return = total_return * 252 / num_days\n",
    "\n",
    "    # Calculate average daily return and annualize it\n",
    "    daily_return = returns.mean() * len(net_worth_list) / num_days\n",
    "    annualized_daily_return = 252 * daily_return\n",
    "\n",
    "    # Calculate annualized standard deviation (sigma)\n",
    "    annualized_sigma = returns.std() * np.sqrt(252 * len(net_worth_list) / num_days)\n",
    "\n",
    "    # Calculate risk-adjusted return (Sharpe ratio)\n",
    "    sharpe_ratio = annualized_daily_return / annualized_sigma\n",
    "\n",
    "    # Plotting the net worth list\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(net_worth_list)\n",
    "    plt.title(\"Net Worth Over Time\")\n",
    "    plt.xlabel(\"Time (Days)\")\n",
    "    plt.ylabel(\"Net Worth\")\n",
    "\n",
    "    # Plotting the drawdown\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(daily_drawdown)\n",
    "    plt.title(\"Drawdown Over Time\")\n",
    "    plt.xlabel(\"Time (Days)\")\n",
    "    plt.ylabel(\"Drawdown\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Creating a DataFrame for the metrics\n",
    "    metrics = pd.DataFrame({\n",
    "        'Metric': ['Annualized Total Return', 'Annualized Daily Return', 'Annualized Sigma', 'Sharpe Ratio', 'Max Drawdown', 'Turnover Rate'],\n",
    "        'Value': [f\"{round(annualized_total_return * 100, 4)}%\", f\"{round(annualized_daily_return * 100, 4)}%\", \n",
    "                  f\"{round(annualized_sigma * 100, 4)}%\", f\"{round(sharpe_ratio, 4)}\", f\"{round(max_drawdown * 100, 4)}%\", f\"{round(turnover_rate * 100, 4)}%\"]\n",
    "    })\n",
    "\n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb4ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_value = 14483.7497 # Initial value of the investment\n",
    "metrics = calculate_financial_metrics(net_worth_list, num_days, initial_value, action_list)\n",
    "print(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "271a3cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "actions = [action[0] for action in action_list]\n",
    "\n",
    "# Create a DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'Net Worth': net_worth_list,\n",
    "    'Action': actions\n",
    "}, index=testing_data.index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da4eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output to CSV\n",
    "df.to_csv('net_worth_actions_LTC.csv', index_label='Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77f42b81",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
